{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bdce9c0",
   "metadata": {},
   "source": [
    "This notebook calculates the PraNet weighted cross-entropy loss for the pre-trained model, cross-entropy fine-tuned model, and the conformal risk training model on the polyp dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef600c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7882c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import torch.utils.data\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from polyps import pranet_utils\n",
    "from polyps.dataloader import get_loaders\n",
    "from polyps.PraNet_Res2Net import PraNet\n",
    "\n",
    "Device = str | torch.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2578f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "CKPT_PATH = 'polyps/PraNet-19.pth'\n",
    "SEEDS = range(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24458797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pranet_loss(\n",
    "    model: PraNet,\n",
    "    loader: torch.utils.data.DataLoader,\n",
    "    device: Device,\n",
    ") -> float:\n",
    "    total_pranet_loss = 0.\n",
    "    with torch.no_grad():\n",
    "        for images, masks in loader:\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            masks = masks.to(device=device, dtype=torch.float32, non_blocking=True)\n",
    "            pranet_loss = pranet_utils.pranet_loss(model, images, masks).item()\n",
    "            total_pranet_loss += pranet_loss * len(images)\n",
    "        pranet_loss = total_pranet_loss / len(loader.dataset)\n",
    "\n",
    "    return pranet_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e560cc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:2'\n",
    "\n",
    "model = PraNet()\n",
    "model.load_state_dict(torch.load(CKPT_PATH, weights_only=True))\n",
    "model.to(device=device)\n",
    "\n",
    "pranet_losses = []\n",
    "for seed in tqdm(SEEDS):\n",
    "    loaders = get_loaders(splits=('test',), batch_size=64, seed=seed)\n",
    "    pranet_loss = get_pranet_loss(model, loader=loaders['test'], device=device)\n",
    "    pranet_losses.append(pranet_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c6335d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pranet_loss_df = pd.DataFrame({'pretrain': pranet_losses}, index=pd.Index(SEEDS, name='seed'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e72e071",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [0.01, 0.05, 0.1]\n",
    "lrs = [1e-2, 1e-3, 1e-4, 1e-5, 1e-6]\n",
    "\n",
    "rows = []\n",
    "for s, lr in itertools.product(SEEDS, lrs):\n",
    "    basename = f'lr{lr:.2g}_s{s}'\n",
    "    try:\n",
    "        with open(f'out/polyps/trainbase/{basename}.json') as f:\n",
    "            result = json.load(f)\n",
    "        assert result['seed'] == s\n",
    "        assert result['lr'] == lr\n",
    "        assert set(alphas).issubset(result['alphas'])\n",
    "        rows.append({\n",
    "            'seed': s,\n",
    "            'lr': lr,\n",
    "            'val_loss': result['val_loss'],\n",
    "            'ckpt_path': f'out/polyps/trainbase/{basename}.pt'\n",
    "        })\n",
    "    except FileNotFoundError:\n",
    "        print(f'File not found: {basename}.json')\n",
    "        continue\n",
    "\n",
    "df_trainbase = pd.DataFrame(rows)\n",
    "best_hps = df_trainbase.groupby('seed')['val_loss'].idxmin().values.tolist()\n",
    "df_trainbase_best = df_trainbase.loc[best_hps].reset_index().set_index('seed')\n",
    "display(df_trainbase_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbad305",
   "metadata": {},
   "outputs": [],
   "source": [
    "pranet_losses = []\n",
    "for seed in tqdm(SEEDS):\n",
    "    ckpt_path = df_trainbase_best.loc[seed, 'ckpt_path']\n",
    "    model.load_state_dict(torch.load(ckpt_path, weights_only=True))\n",
    "    loaders = get_loaders(splits=('test',), batch_size=64, seed=seed)\n",
    "    pranet_loss = get_pranet_loss(model, loader=loaders['test'], device=device)\n",
    "    pranet_losses.append(pranet_loss)\n",
    "\n",
    "pranet_loss_df['cross-entropy'] = pranet_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b42036",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [0.01, 0.05, 0.1]\n",
    "lrs = [1e-2, 1e-3, 1e-4, 1e-5, 1e-6]\n",
    "\n",
    "rows = []\n",
    "for a, s, lr in itertools.product(alphas, SEEDS, lrs):\n",
    "    basename = f'a{a:.2f}_lr{lr:.2g}_s{s}'\n",
    "    try:\n",
    "        with open(f'out/polyps/e2ecrc/{basename}.json') as f:\n",
    "            result = json.load(f)\n",
    "        assert result['seed'] == s\n",
    "        assert result['lr'] == lr\n",
    "        assert result['alpha'] == a\n",
    "        rows.append({\n",
    "            'alpha': a,\n",
    "            'seed': s,\n",
    "            'lr': lr,\n",
    "            'val_fpr': result['val_fpr'],\n",
    "            'ckpt_path': f'out/polyps/e2ecrc/{basename}.pt'\n",
    "        })\n",
    "    except FileNotFoundError:\n",
    "        print(f'File not found: {basename}.json')\n",
    "        continue\n",
    "\n",
    "df_e2ecrc = pd.DataFrame(rows)\n",
    "best_hps = df_e2ecrc.groupby(['alpha', 'seed'])['val_fpr'].idxmin().values.tolist()\n",
    "df_e2ecrc_best = df_e2ecrc.loc[best_hps].reset_index().set_index(['alpha', 'seed'])\n",
    "display(df_e2ecrc_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4ff52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in alphas:\n",
    "    pranet_losses = []\n",
    "    for seed in tqdm(SEEDS):\n",
    "        ckpt_path = df_e2ecrc_best.loc[(a, seed), 'ckpt_path']\n",
    "        model.load_state_dict(torch.load(ckpt_path, weights_only=True))\n",
    "        loaders = get_loaders(splits=('test',), batch_size=64, seed=seed)\n",
    "        pranet_loss = get_pranet_loss(model, loader=loaders['test'], device=device)\n",
    "        pranet_losses.append(pranet_loss)\n",
    "\n",
    "    pranet_loss_df[f'e2e-crc Î±{a:.2f}'] = pranet_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0271dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pranet_loss_df.to_csv('out/polyps/pranet_losses.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0167320d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pranet_loss_df = pd.read_csv('out/polyps/pranet_losses.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea3ed1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pranet_loss_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e419e527",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pranet_loss_df.agg(['mean', 'std']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "e2ecrc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
