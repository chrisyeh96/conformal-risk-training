{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5369de19",
   "metadata": {},
   "source": [
    "This notebook examines the effect of varying the hyperparameter $t$ on the mean task loss and financial CVaR tail risk on the battery storage problem, for the pre-trained MLP models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5a2198",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48752318",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Iterable, Mapping\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from models.mlp import MLP\n",
    "from storage.data import get_tensors, get_train_calib_split\n",
    "from storage.problems import (\n",
    "    StorageConstants, StorageProblemNonRobust, StorageProblemLambda)\n",
    "from run_storage import cvar, get_zs\n",
    "\n",
    "Device = str | torch.device\n",
    "\n",
    "INPUT_DIM = 101  # including future_temp\n",
    "Y_DIM = 24\n",
    "MAX_PRETRAIN_EPOCHS = 500\n",
    "MAX_FINETUNE_EPOCHS = 100\n",
    "BATCH_SIZE = 400\n",
    "PSEUDOCAILB_SIZE = 200\n",
    "SEEDS = range(10)\n",
    "LOG_PRICES = False\n",
    "LABEL_NOISE = 20\n",
    "\n",
    "STORAGE_CONSTS = [\n",
    "    StorageConstants(lam=0.1, eps=.05),\n",
    "]\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "out_dir = 'out/storage_mlp_shuffle/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a811d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lams_dt(\n",
    "    tensors_dict: Mapping[str, Tensor], model: MLP, prob: StorageProblemNonRobust,\n",
    "    device: Device, alphas: Iterable[float], deltas: Iterable[float],\n",
    "    dts: Iterable[float] = [-5, -2, -1, 0, 1, 2, 5], dt_relative: bool = False\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns a DataFrame with columns:\n",
    "        alpha, delta, lambda, t, dt, task loss (on calib split), CVaR (on calib split)\n",
    "    Note that `t` includes the `dt` offset.\n",
    "\n",
    "    Args:\n",
    "        tensors_dict: dict with keys 'X_train', 'X_calib', 'Y_train', 'Y_calib'\n",
    "        model: trained MLP model\n",
    "        prob: problem instance\n",
    "        device: 'cpu', 'cuda', or 'cuda:X' where X is the GPU index\n",
    "        alphas: risk bounds\n",
    "        deltas: quantile levels\n",
    "        dts: offsets to apply to `t` tuned on training set\n",
    "        dt_relative: whether `dt` is a relative or absolute adjustment to the optimal `t`\n",
    "            found on the training set. Relative means `t_new = (1 + dt) * t`.\n",
    "            Absolute means `t_new = t + dt`.\n",
    "    \"\"\"\n",
    "    X_train = tensors_dict['X_train'].to(device, non_blocking=True)\n",
    "    X_val = tensors_dict['X_calib'].to(device, non_blocking=True)\n",
    "    Y_train_np = tensors_dict['Y_train'].cpu().numpy()\n",
    "    Y_val_np = tensors_dict['Y_calib'].cpu().numpy()\n",
    "\n",
    "    # get decision variables\n",
    "    with torch.no_grad():\n",
    "        model.eval().to(device)\n",
    "        pred_np_train = model(X_train).cpu().numpy()\n",
    "        pred_np_val = model(X_val).cpu().numpy()\n",
    "    z_in_train, z_out_train, z_net_train = get_zs(prob, pred_np_train)\n",
    "    z_in_val, z_out_val, z_net_val = get_zs(prob, pred_np_val)\n",
    "\n",
    "    max_lambda_prob_var_t = StorageProblemLambda(\n",
    "        T=Y_DIM, const=prob.const,\n",
    "        y=Y_train_np, y_mean=prob.y_mean, y_std=prob.y_std,\n",
    "        z_in=z_in_train, z_out=z_out_train, z_net=z_net_train, quad=False, t_fixed=False)\n",
    "\n",
    "    max_lambda_prob_fixed_t = StorageProblemLambda(\n",
    "        T=Y_DIM, const=prob.const,\n",
    "        y=Y_val_np, y_mean=prob.y_mean, y_std=prob.y_std,\n",
    "        z_in=z_in_val, z_out=z_out_val, z_net=z_net_val, quad=False, t_fixed=True)\n",
    "\n",
    "    rows = []\n",
    "    for alpha, delta in itertools.product(alphas, deltas):\n",
    "        max_lambda_prob_var_t.solve(alpha, delta)\n",
    "        assert max_lambda_prob_var_t.t.value is not None\n",
    "        t = max_lambda_prob_var_t.t.value.item()\n",
    "\n",
    "        for dt in dts:\n",
    "            if dt_relative:\n",
    "                t_new = (1 + dt) * t\n",
    "            else:\n",
    "                t_new = t + dt\n",
    "\n",
    "            if t_new < 0:\n",
    "                rows.append({\n",
    "                    'alpha': alpha, 'delta': delta, 'dt': dt,\n",
    "                    'lambda': np.nan, 't': t_new,\n",
    "                    'task loss': np.nan, 'CVaR': np.nan\n",
    "                })\n",
    "                continue\n",
    "\n",
    "            λ = max_lambda_prob_fixed_t.solve(alpha, delta, t=t_new)\n",
    "            if λ == 0.:\n",
    "                val_task_loss = 0.\n",
    "                val_cvar = 0.\n",
    "            else:\n",
    "                task_losses = prob.task_loss(\n",
    "                    z_in_val * λ, z_out_val * λ, z_net_val * λ,\n",
    "                    y=Y_val_np, is_standardized=True)\n",
    "                financial_losses = prob.financial_loss(\n",
    "                    z_in_val * λ, z_out_val * λ, y=Y_val_np, is_standardized=True)\n",
    "                assert isinstance(task_losses, np.ndarray)\n",
    "                assert isinstance(financial_losses, np.ndarray)\n",
    "                val_task_loss = np.mean(task_losses).item()\n",
    "                val_cvar = cvar(financial_losses, q=delta)\n",
    "\n",
    "            rows.append({\n",
    "                'alpha': alpha, 'delta': delta, 'dt': dt,\n",
    "                'lambda': λ,\n",
    "                't': t_new,\n",
    "                'task loss': val_task_loss,\n",
    "                'CVaR': val_cvar\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(rows).set_index(['alpha', 'delta', 'dt'])\n",
    "\n",
    "\n",
    "def crc_dt(\n",
    "    shuffle: bool, future_temp: bool, label_noise: float, const: StorageConstants,\n",
    "    alphas: Iterable[float], deltas: Iterable[float],\n",
    "    dts: Iterable[float], dt_relative: bool,\n",
    "    seed: int, saved_ckpt_fmt: str, device: Device\n",
    ") -> list[dict[str, float]]:\n",
    "    \"\"\"\n",
    "    Post-hoc CRC. Always call this function within a torch.no_grad() context.\n",
    "\n",
    "    Args:\n",
    "        dts: list of offsets to apply to `t` tuned on training set\n",
    "        dt_relative: whether `dt` is a relative (True) or absolute (False) adjustment to\n",
    "            the optimal `t`\n",
    "\n",
    "    Returns:\n",
    "        list of dicts, one per (alpha, delta) pair, with keys:\n",
    "            seed, alpha, delta, lambda, task loss, cvar\n",
    "    \"\"\"\n",
    "    tensors, y_info = get_tensors(\n",
    "        shuffle=shuffle, log_prices=LOG_PRICES, future_temp=future_temp,\n",
    "        label_noise=label_noise)\n",
    "    assert isinstance(y_info, tuple)\n",
    "    y_mean, y_std = y_info\n",
    "    tensors_cv, _ = get_train_calib_split(tensors, seed=seed)\n",
    "\n",
    "    prob = StorageProblemNonRobust(T=Y_DIM, y_mean=y_mean, y_std=y_std, const=const)\n",
    "\n",
    "    # load the model\n",
    "    model = MLP(input_dim=tensors['X_test'].shape[1], y_dim=Y_DIM)\n",
    "    saved_ckpt_path = saved_ckpt_fmt.format(seed=seed)\n",
    "    model.load_state_dict(torch.load(saved_ckpt_path, weights_only=True))\n",
    "    model.eval().to(device)\n",
    "\n",
    "    calib_df = get_lams_dt(\n",
    "        tensors_dict=tensors_cv, model=model,\n",
    "        prob=prob, device=device, alphas=alphas, deltas=deltas,\n",
    "        dts=dts, dt_relative=dt_relative)\n",
    "\n",
    "    # use lambdas on test set\n",
    "    with torch.no_grad():\n",
    "        model.eval().to(device)\n",
    "        pred_np = model(tensors['X_test'].to(device)).cpu().numpy()  # type: ignore\n",
    "    z_in, z_out, z_net = get_zs(prob, preds=pred_np)\n",
    "    y_test = tensors['Y_test'].cpu().numpy()  # type: ignore\n",
    "    rows = []\n",
    "    for (alpha, delta, dt) in calib_df.index:\n",
    "        t = calib_df.loc[(alpha, delta, dt), 't']\n",
    "        λ = calib_df.loc[(alpha, delta, dt), 'lambda']\n",
    "        if np.isnan(λ):\n",
    "            # if λ is NaN, we cannot compute task loss or CVaR\n",
    "            rows.append({\n",
    "                'seed': seed, 'alpha': alpha, 'delta': delta, 'dt': dt, 't': t,\n",
    "                'lambda': np.nan,\n",
    "                'task loss': np.nan,\n",
    "                'task losses': np.nan,\n",
    "                'cvar': np.nan\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        task_losses = prob.task_loss(z_in * λ, z_out * λ, z_net * λ, y=y_test, is_standardized=True)\n",
    "        financial_losses = prob.financial_loss(z_in * λ, z_out * λ, y=y_test, is_standardized=True)\n",
    "        assert isinstance(task_losses, np.ndarray)\n",
    "        assert isinstance(financial_losses, np.ndarray)\n",
    "        rows.append({\n",
    "            'seed': seed, 'alpha': alpha, 'delta': delta, 'dt': dt, 't': t, 'lambda': λ,\n",
    "            'task loss': np.mean(task_losses).item(),\n",
    "            'task losses': task_losses,\n",
    "            'financial losses': financial_losses,\n",
    "            'cvar': cvar(financial_losses, q=delta)\n",
    "        })\n",
    "\n",
    "    return rows\n",
    "\n",
    "\n",
    "def mean_std(row: pd.Series, mean_fmt: str = '{:.2g}', std_fmt: str = '{:.2g}') -> str:\n",
    "    mean = row['mean']\n",
    "    std = row['std']\n",
    "    if np.isnan(mean):\n",
    "        assert np.isnan(std)\n",
    "        return \"nan\"\n",
    "    return f'{mean_fmt.format(mean)} ± {std_fmt.format(std)}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6f3061",
   "metadata": {},
   "source": [
    "## Absolute $\\Delta t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d99be8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rows: list[dict[str, float]] = []\n",
    "saved_ckpt_fmt = os.path.join(out_dir, 'mlp_s{seed}.pt')\n",
    "for s in tqdm(SEEDS):\n",
    "    crc_results = crc_dt(\n",
    "        seed=s, shuffle=True, future_temp=False,\n",
    "        label_noise=LABEL_NOISE, const=STORAGE_CONSTS[0],\n",
    "        alphas=[2, 5, 10], deltas=[.9, .95, .99],\n",
    "        dts=[-5, -2, -1, 0, 1, 2, 5], dt_relative=False,\n",
    "        saved_ckpt_fmt=saved_ckpt_fmt, device='cuda:1')\n",
    "    all_rows.extend(crc_results)\n",
    "# save results to file\n",
    "df = pd.DataFrame(all_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341c8643",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['task losses']\n",
    "del df['financial losses']\n",
    "df.to_csv(os.path.join(out_dir, 'crc_vary_t_absolute.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36decb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(out_dir, 'crc_vary_t_absolute.csv'))\n",
    "df = df.rename(columns={'delta': 'δ', 'alpha': 'α', 'dt': 'Δt', 'lambda': 'λ'})\n",
    "df = df.set_index(['α', 'δ', 'Δt', 'seed'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822f8aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = (\n",
    "    df[['t', 'task loss', 'cvar']]\n",
    "    .groupby(['α', 'δ', 'Δt'])\n",
    "    .agg(['mean', 'std'])\n",
    ")\n",
    "\n",
    "with pd.option_context('display.max_rows', 100):\n",
    "    # display(pd.DataFrame({\n",
    "    #     'task loss': summary['task loss'].apply(mean_std, axis=1),\n",
    "    #     'cvar': summary['cvar'].apply(mean_std, axis=1)\n",
    "    # }))\n",
    "\n",
    "    fmt = '{:.1f}'\n",
    "    kwargs = {'mean_fmt': fmt, 'std_fmt': fmt}\n",
    "\n",
    "    print('t')\n",
    "    print(\n",
    "        summary['t'].apply(mean_std, axis=1, **kwargs).unstack(['α', 'δ']).to_latex()\n",
    "    )\n",
    "    print()\n",
    "\n",
    "    print('Task loss:')\n",
    "    print(\n",
    "        summary['task loss'].apply(mean_std, axis=1, **kwargs).unstack(['α', 'δ']).to_latex()\n",
    "    )\n",
    "    print()\n",
    "    print('CVaR:')\n",
    "    print(\n",
    "        summary['cvar'].apply(mean_std, axis=1, **kwargs).unstack(['α', 'δ']).to_latex()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b62dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long = df[['task loss', 'cvar']]\n",
    "df_long.columns.name = 'metric'\n",
    "df_long = df_long.stack().to_frame(name='value')\n",
    "df_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846ac0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(\n",
    "    data=df_long, x='Δt', y='value', hue='α',\n",
    "    col='δ', row='metric',\n",
    "    sharey=False, kind='box', height=2.8, aspect=1.4,\n",
    "    width=0.5\n",
    ")\n",
    "\n",
    "# Iterate through the axes and add vertical lines\n",
    "for ax in g.axes.flatten():\n",
    "    ticks = ax.get_xticks()\n",
    "    for i in range(1, len(ticks)):\n",
    "        ax.axvline((ticks[i] + ticks[i-1])/2, color=\"gray\", linestyle=\"--\", linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e1ac66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn.objects as so\n",
    "\n",
    "# (\n",
    "#     so.Plot(df_long, x='Δt', y='value', color='α')\n",
    "#     .add(so.Bar(), so.Agg(), so.Dodge())\n",
    "#     .facet(col='δ', row='metric')\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1de01c",
   "metadata": {},
   "source": [
    "# Relative $\\Delta t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52937d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rows: list[dict[str, float]] = []\n",
    "saved_ckpt_fmt = os.path.join(out_dir, 'mlp_s{seed}.pt')\n",
    "for s in tqdm(SEEDS):\n",
    "    crc_results = crc_dt(\n",
    "        seed=s, shuffle=True, future_temp=False,\n",
    "        label_noise=LABEL_NOISE, const=STORAGE_CONSTS[0],\n",
    "        alphas=[2, 5, 10], deltas=[.9, .95, .99],\n",
    "        dts=[-0.5, -0.2, -0.1, 0, 0.1, 0.2, 0.5], dt_relative=True,\n",
    "        saved_ckpt_fmt=saved_ckpt_fmt, device='cuda:1')\n",
    "    all_rows.extend(crc_results)\n",
    "# save results to file\n",
    "df = pd.DataFrame(all_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d228270",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['task losses']\n",
    "del df['financial losses']\n",
    "df.to_csv(os.path.join(out_dir, 'crc_vary_t_relative.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3452ecd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(out_dir, 'crc_vary_t_relative.csv'))\n",
    "df = df.rename(columns={'delta': 'δ', 'alpha': 'α', 'dt': 'Δt', 'lambda': 'λ'})\n",
    "df = df.set_index(['α', 'δ', 'Δt', 'seed'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca078ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = (\n",
    "    df[['t', 'task loss', 'cvar']]\n",
    "    .groupby(['α', 'δ', 'Δt'])\n",
    "    .agg(['mean', 'std'])\n",
    ")\n",
    "\n",
    "with pd.option_context('display.max_rows', 100):\n",
    "    # display(pd.DataFrame({\n",
    "    #     'task loss': summary['task loss'].apply(mean_std, axis=1),\n",
    "    #     'cvar': summary['cvar'].apply(mean_std, axis=1)\n",
    "    # }))\n",
    "\n",
    "    fmt = '{:.1f}'\n",
    "    kwargs = {'mean_fmt': fmt, 'std_fmt': fmt}\n",
    "\n",
    "    print('t')\n",
    "    print(\n",
    "        summary['t'].apply(mean_std, axis=1, **kwargs).unstack(['α', 'δ']).to_latex()\n",
    "    )\n",
    "    print()\n",
    "\n",
    "    print('Task loss:')\n",
    "    print(\n",
    "        summary['task loss'].apply(mean_std, axis=1, **kwargs).unstack(['α', 'δ']).to_latex()\n",
    "    )\n",
    "    print()\n",
    "    print('CVaR:')\n",
    "    print(\n",
    "        summary['cvar'].apply(mean_std, axis=1, **kwargs).unstack(['α', 'δ']).to_latex()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173bf5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long = df[['task loss', 'cvar']]\n",
    "df_long.columns.name = 'metric'\n",
    "df_long = df_long.stack().to_frame(name='value')\n",
    "df_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275c438a",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(\n",
    "    data=df_long, x='Δt', y='value', hue='α',\n",
    "    col='δ', row='metric',\n",
    "    sharey=False, kind='box', height=2.8, aspect=1.4,\n",
    "    width=0.5\n",
    ")\n",
    "\n",
    "# Iterate through the axes and add vertical lines\n",
    "for ax in g.axes.flatten():\n",
    "    ticks = ax.get_xticks()\n",
    "    for i in range(1, len(ticks)):\n",
    "        ax.axvline((ticks[i] + ticks[i-1])/2, color=\"gray\", linestyle=\"--\", linewidth=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "e2ecrc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
